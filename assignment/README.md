# ğŸ­ Beyond the Screen: Your Digital Footprint as Persona

> â€œReconstruct real Reddit personas with explainable AI â€“ powered by embeddings, vector search, and local language models.â€


![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![FAISS](https://img.shields.io/badge/FAISS-VectorSearch-orange)
![SentenceTransformers](https://img.shields.io/badge/SentenceTransformer-Embeddings-purple)
![Ollama](https://img.shields.io/badge/Ollama-Mistral_7B-black)
![RAG](https://img.shields.io/badge/Architecture-RAG-brightgreen)
![Reddit](https://img.shields.io/badge/API-Reddit-blueviolet)
![Contributions Welcome](https://img.shields.io/badge/Contributions-Welcome-yellowgreen)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)
---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Prerequisites

- **Python 3.8+**
- **Git**

---

### 2ï¸âƒ£ Ollama & Mistral Setup (Local LLM)

1. **Install Ollama**  
   - Go to [https://ollama.com/download](https://ollama.com/download)  
   - Download and install for your OS (Windows, macOS, or Linux)
2. **Pull the Mistral model for local inference**  
   Open a terminal and run:
   ollama pull mistral

---

### 3ï¸âƒ£ Install Python Requirements

1. **Clone this repo:**
git clone https://github.com/yourusername/PersonaForge.git
cd PersonaForge

2. **Install dependencies:**
pip install -r requirements.txt

---

### 4ï¸âƒ£ Install SentenceTransformer Model Locally

This project requires the embedding model  
`sentence-transformers/all-MiniLM-L6-v2`  
to be downloaded and stored locally for private and fast processing.

#### Run this setup script in your terminal or Python shell:
from sentence_transformers import SentenceTransformer
SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

This will **download the model to your cache** (`~/.cache/torch/sentence_transformers/` by default).  
No extra step is needed if youâ€™ve done this onceâ€”future runs will use the local copy!

*If you want model files in a custom folder, use:*
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', cache_folder='your/model/path')

Then point `EMBEDDING_MODEL_PATH` in the config to that directory.

---

### 5ï¸âƒ£ Reddit API Credentials

1. Go to [https://www.reddit.com/prefs/apps](https://www.reddit.com/prefs/apps)
2. Create an app ("script" type)
3. Add your `client_id`, `client_secret`, and set a `user_agent`  
   Example is shown in `reddit_persona.py`

---

### 6ï¸âƒ£ Run the Pipeline

In terminal:
python assignment/pyscript final code.py
(remember to change the paths in the code)

To see Full implementation with explanation look at the assigment.ipynb

- The persona profile and all evidence will be saved in `assignment/persona_report.txt`

---

## ğŸ› ï¸ Folder Structure
assignment/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ assignment.ipynb
â””â”€â”€ pyscript final code.py
â”œâ”€â”€ persona_report-1.txt
â”œâ”€â”€ persona_report-2.txt
â””â”€â”€ reddit_user_data-1.json
â””â”€â”€ reddit_user_data-2.json

---

## âš¡ requirements.txt

praw==7.7.1
sentence-transformers==2.2.2
faiss-cpu==1.7.4
numpy==1.24.3
*Ollama and your embedding model are managed outside pip.*

---

## â­ Features

- ğŸ“¨ Scrapes Reddit posts/comments by username or URL.
- ğŸ§® Embeds content semantically with **MiniLM L6**.
- ğŸ” RAG with **local FAISS** vector DB for efficient evidence retrieval.
- ğŸ¤– Local inference with **Mistral LLM via Ollama**.
- ğŸ”— Evidence-rich persona profiles with direct Reddit links.
- ğŸ›¡ï¸ 100% offline/private model execution, no cloud LLM needed.

---


---

## ğŸ¤ Need Help?

- [Ollama Support](https://ollama.com/)
- [Sentence-Transformers Docs](https://www.sbert.net/)
- [Reddit/PRAW Documentation](https://praw.readthedocs.io/)

---
## To contact me 
email: velamalapavankrishna@gmail.com
insta: pavankrishna_v

Thank you! ğŸ§ âœ¨


